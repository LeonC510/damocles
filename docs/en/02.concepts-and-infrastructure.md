# Concepts

Damocles contains a series of abstractions and functional components. Understanding these will help us comprehend how Damocles operates.

## Public Section

### ActorID

`ActorID` is the identifier format for SPs used in Damocles components. It is an integer and corresponds to the number part of the SP's ID address.

For example:

- In the testnet, an SP ID address `t01234` corresponds to an `ActorID` of `1234`.
- In the mainnet, an SP ID address `f02468` corresponds to an `ActorID` of `2468`.



We used a unified identifier format like 'ActorID' to 

- Ensure convenience in recognition and writing
- Avoid confusion that may be caused by network identifiers (`t`, `f`) and type identifiers (`0` in `t0`) in addresses



### objstore

`objstore` is a storage infrastructure abstraction based on object storage patterns.

We know that, in Filecoin, the various actions that interact with data use filesystem-based storage facilities extensively. In practice, we find that other than some relatively basic data access patterns, many features provided by the file system are not used.

Through analysis, we believe:

1. In many scenarios, basic object storage abstractions can already meet the needs of Filecoin.
2. Whether building local large-scale, high-availability distributed storage clusters or using existing commercialized storage solutions, object storage has many options.
3. Existing filesystem-based storage can be interacted with using the object storage interfaces through a simple proxy layer.

Of course, at the algorithm level, since some key processes still do not support abstractions based on object storage (for example `MerkleStore`), we currently only convert the file system to object storage. We hope that in the future, through community promotion of native support for object storage in Filecoin at the algorithm level, users will be able to choose or even mix suitable storage solutions according to their own needs.

### piece store

`piece store` is a storage abstraction used in storage deal sealing scenarios to access the `piece` data of orders.

The `piece` data here refers to the original raw data content issued by the user, without padding and FR32 conversion.

Since `damocles-cluster` does not involve writing `piece` data, it only provides an interface for reading data.

## Damocles-worker Section

### Sealing store

The `sealing store` is local high-speed storage facilities located on the host machine where the `damocles-worker` resides. It is used to temporarily store data files generated during the sector sealing process. Typically comprised of high-performance local storage devices (such as nvme).

The sealing store follows these usage guidelines:

- Each sector uniquely corresponds to a single `sealing store`
- A `sealing store` will only contain one sector at any given time.

Each `sealing store` contains two subdirectories - `meta` and `data` - which store the state and sealing data of the sector in progress, respectively. This ensures that sector states do not interfere with each other across `sealing stores`. Even if some `sealing store` underlying storage devices fail, the impact is limited to the `sealing store` containing them.

Typically, `sealing store` is planned according to the available storage resources on the current host machine.

### Remote store

The `remote store` is the permanent storage facility for sector data, typically a storage cluster.

Currently in `damocles-worker`, the `remote store` is implemented as an object storage interface sealing over the filesystem.

After sealing is complete, sector data awaiting on-chain commitment will be moved from the `sealing store` to the `remote store`.

In fact, the `remote store` is more relative to the local `sealing store`. Both the `damocles-manager` and `damocles-worker` need to be able to access this storage infrastructure.

### Processor

The `processor` is the executor of the sector sealing steps. Typically, each independent step corresponds to a type of `processor`, such as the `pc1 processor`, `c2 processor`, etc. Users can configure the parallelism for each type of processor.

Usually, `processor` is planned according to the available computational resources on the current host machine.

##### External processor

The `external processor` is a special type of `processor` that exists as a subprocess. Through a defined protocol, it interacts with the main process to exchange task context and executes a specific sealing step.

The `external processor` enables `damocles` to leverage the OS interfaces to configure and isolate computational resources for subprocesses, such as:

- Specifying `cpu sets` for the `pc1 processor` via `cgroup` to avoid `cpu` resource contention between sectors in the `pc1` phase.
- Specifying memory allocation preference via `numa` for the `pc1 processor` to reduce memory access latency in the `pc1` phase, and improve cache prefetch efficiency in `multicore_sdr` mode.
- Binding unique available GPUs and separating lock files for multiple `c2 processors` via Nvidia default GPU-related environment variables

And many other flexible combinations.

In addition to convenient configuration and isolation of resources, the `external processor` also enables **non-generic or non-public executor** implementations. Any executable program meeting the context interaction protocol can be integrated into the sealing workflow as an `external processor `implementation. This facilitates easy integration of options such as:

- Highly customized `c2 processors`
 - GPU outsourced `pc2 processor` or `c2 processor`

Users can freely choose various customized `external processors` for combination, unconstrained by who develops and maintains the specific `external processor`.

#### relationship between sealing stores, processors, and sectors

In the previous sections we mentioned that `sealing store` and `processor` is planned separately based on storage and compute resources respectively. Does this mean that they don't need to maintain a 1:1 ratio?

The answer is yes, for the following reasons:

At any given stage, the resource that a `sector` occupied is the combination of compute resources (`processor`) and storage resources (`sealing store`).

In the sealing workflow of `damocles-worker`, when a `sector` transitions from one stage to the next, it releases the compute resources it previously occupied, and tries to acquire compute resources needed for the next stage. The released compute resources can be readily allocated to other waiting `sectors`.

For example,

typically, considering costs and hardware specs, the number of planned `sealing store` is often much higher than the number of planned `p1 processor`. In the sealing of `damocles-worker`, if a `sector` finishes computation in the `p1` stage, the released `p1 processor` can be used for `sectors` on other waiting `sealing store`.

This enables high density utilization of hardware resources.

## Damocles-manager Section

### Basic Service API

These are services `damocles` relied upon and definitions of interfaces.

These services and interfaces provide `damocles` with basic capabilities for interacting with the chain and other participants.

#### chain.API

This is a set of chain-related interface definitions defined in `venus/venus-shared`. It mainly provides `damocles` with basic chain service interfaces.

#### messager.API

This is a set of message-related interface definitions defined in `venus/venus-shared`. It mainly provides `damocles` with basic capabilities for sending messages, confirming on-chain, and executing results.

#### market.API

This is a set of order-related interface definitions defined in `venus/venus-shared`. It mainly provides `damocles` with basic capabilities for order allocation and obtaining order data.

### RandomnessAPI

This is a simple sealing for `chain.API` that is mainly used to provide randomness information needed for sector sealing and maintaining.

This sealing layer allows `damocles-worker` and other modules to just obtain the required results as needed, without having to worry about the underlying request objects (Drand or Filecoin) or formats.

### MinerInfoAPI

This is a sealing for `chain.API` that mainly provides the information of `SP` granularity.

### SectorManager

This is the module for managing sector allocation. It is mainly responsible for assigning sector numbers based on the parameters submitted by `damocles-worker`.

It can support multiple `SP` and different sector sizes.

### DealManager

This is the module for managing orders. It is mainly responsible for assigning order pieces that can fit into empty allocated sectors, as well as releasing orders in failed sectors.

### CommitmentManager

This is the module for submitting sector messages on chain. It is mainly responsible for submitting PreCommit and ProveCommit messages individually or in aggregated form based on predefined strategies and observing the on-chain results.

### SectorStateManager

This is the module for managing the state of sectors in progress. It is mainly responsible for receiving status and exception updates from `damocles-worker`.

### SectorIndexer

This is the module for managing the location of completed sectors. It is mainly used for locating specified sectors, commonly used during `PoSt` computation.